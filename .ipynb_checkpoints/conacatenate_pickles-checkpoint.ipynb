{
 "metadata": {
  "name": "",
  "signature": "sha256:033420463a787285140b6046b7c8af9037ba98501940b4df0c28a5cb22095920"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Concatenate all pickles"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim import corpora, models, similarities\n",
      "\n",
      "\n",
      "import pickle as pkl\n",
      "def save_data(fname, data):\n",
      "    output = open(fname, 'wb')\n",
      "    pkl.dump(data, output)\n",
      "    output.close()  \n",
      "    \n",
      "    \n",
      "def load_data(fname):\n",
      "    inp = open(fname, 'rb')\n",
      "    d = pkl.load(inp)\n",
      "    inp.close()\n",
      "    return d\n",
      "pkls = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14']\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "dct = corpora.Dictionary()\n",
      "for p in pkls:\n",
      "    n = \"../texts\" + p + \".pkl\"\n",
      "    print \"adding pickle \" + n\n",
      "    data = load_data(n)\n",
      "    texts = [x[1] for x in data]\n",
      "    dct.add_documents(texts)\n",
      "print \"saving dict...\"\n",
      "save_data('../dictionary.pkl', dct)\n",
      "print \"Finish\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "adding pickle ../texts01.pkl\n",
        "adding pickle ../texts02.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "adding pickle ../texts03.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "adding pickle ../texts04.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "adding pickle ../texts05.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "adding pickle ../texts06.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "adding pickle ../texts07.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "adding pickle ../texts08.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "adding pickle ../texts09.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "adding pickle ../texts10.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "adding pickle ../texts11.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "adding pickle ../texts12.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "adding pickle ../texts13.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "adding pickle ../texts14.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "saving dict..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finish"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dct = load_data('../dictionary.pkl')\n",
      "dct.filter_extremes(no_below=10, no_above=0.3, keep_n=None)\n",
      "dct.compactify()\n",
      "save_data('../dict_compacted.pkl', dct)\n",
      "print \"Finished\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finished\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Load dict'\n",
      "#dct = load_data('../dict_compacted.pkl')\n",
      "dct = load_data('../dictionary.pkl')\n",
      "bow = []\n",
      "for p in pkls:\n",
      "    n = \"../texts\" + p + \".pkl\"\n",
      "    print \"Processing pickle \" + n\n",
      "    data = load_data(n)\n",
      "    texts = [x[1] for x in data]\n",
      "    for text in texts:\n",
      "        bow.append(dct.doc2bow(text))\n",
      "print \"saving dict...\"\n",
      "save_data('../corpora2.pkl', bow)\n",
      "print \"Finished\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load dict\n",
        "Processing pickle ../texts01.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing pickle ../texts02.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing pickle ../texts03.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing pickle ../texts04.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing pickle ../texts05.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing pickle ../texts06.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing pickle ../texts07.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing pickle ../texts08.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing pickle ../texts09.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing pickle ../texts10.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing pickle ../texts11.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing pickle ../texts12.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing pickle ../texts13.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing pickle ../texts14.pkl"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "saving dict..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Load data'\n",
      "#dct = load_data('../dict_compacted.pkl')\n",
      "#crp = load_data('../corpora1.pkl')\n",
      "dct = load_data('../dictionary.pkl')\n",
      "crp = load_data('../corpora2.pkl')\n",
      "\n",
      "print 'Make LDA'\n",
      "lda = models.ldamodel.LdaModel(crp, id2word=dct, num_topics=100, alpha='auto',  passes=5, iterations=10)\n",
      "save_data('../lda2.pkl', lda)\n",
      "print 'Finished'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load data\n",
        "Make LDA"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/tesla/.local/lib/python2.7/site-packages/gensim/models/ldamodel.py:1023: RuntimeWarning: divide by zero encountered in log\n",
        "  diff = np.log(self.expElogbeta)\n",
        "/home/tesla/.local/lib/python2.7/site-packages/gensim/models/ldamodel.py:690: RuntimeWarning: overflow encountered in add\n",
        "  sstats[:, ids] += np.outer(expElogthetad.T, cts / phinorm)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/tesla/.local/lib/python2.7/site-packages/gensim/models/ldamodel.py:676: RuntimeWarning: overflow encountered in divide\n",
        "  gammad = self.alpha + expElogthetad * np.dot(cts / phinorm, expElogbetad.T)\n",
        "/home/tesla/.local/lib/python2.7/site-packages/gensim/models/ldamodel.py:700: RuntimeWarning: invalid value encountered in multiply\n",
        "  sstats *= self.expElogbeta\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/tesla/.local/lib/python2.7/site-packages/gensim/models/ldamodel.py:138: RuntimeWarning: invalid value encountered in greater\n",
        "  if all(rho * dprior + prior > 0):\n",
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:updated prior not positive\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Finished"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyLDAvis.gensim\n",
      "\n",
      "print 'Load data'\n",
      "#dct = load_data('../dict_compacted.pkl')\n",
      "#crp = load_data('../corpora1.pkl')\n",
      "#lda = load_data('../lda1.pkl')\n",
      "\n",
      "dct = load_data('../dictionary.pkl')\n",
      "crp = load_data('../corpora2.pkl')\n",
      "lda = load_data('../lda2.pkl')\n",
      "\n",
      "# viz\n",
      "data = pyLDAvis.gensim.prepare(lda, crp, dct)\n",
      "pyLDAvis.display(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Load data\n"
       ]
      },
      {
       "ename": "ValidationError",
       "evalue": "\n * Not all rows (distributions) in topic_term_dists sum to 1.\n * Not all rows (distributions) in doc_topic_dists sum to 1.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-3-9c360acb5a98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# viz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/tesla/.local/lib/python2.7/site-packages/pyLDAvis/gensim.pyc\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(topic_model, corpus, dictionary, doc_topic_dist, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \"\"\"\n\u001b[1;32m    120\u001b[0m     \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_topic_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvis_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/home/tesla/.local/lib/python2.7/site-packages/pyLDAvis/_prepare.pyc\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(topic_term_dists, doc_topic_dists, doc_lengths, vocab, term_frequency, R, lambda_step, mds, n_jobs, plot_opts, sort_topics)\u001b[0m\n\u001b[1;32m    372\u001b[0m    \u001b[0mdoc_lengths\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0m_series_with_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'doc_length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m    \u001b[0mvocab\u001b[0m            \u001b[0;34m=\u001b[0m \u001b[0m_series_with_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vocab'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m    \u001b[0m_input_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_term_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_topic_dists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_frequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m    \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/home/tesla/.local/lib/python2.7/site-packages/pyLDAvis/_prepare.pyc\u001b[0m in \u001b[0;36m_input_validate\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     63\u001b[0m    \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_input_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValidationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m' * '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValidationError\u001b[0m: \n * Not all rows (distributions) in topic_term_dists sum to 1.\n * Not all rows (distributions) in doc_topic_dists sum to 1."
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dct = load_data('../dict_compacted.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = 0\n",
      "for d in dct.items():\n",
      "    print d[0], d[1]\n",
      "    i += 1\n",
      "    if i >100:\n",
      "        break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "204799 \u0433\u043e\u043d\u0434\u0443\u0440\u0430\u0441\u0441\u043a\u0438\u0439\n",
        "169816 \u043f\u0440\u0438\u0441\u043b\u0443\u0436\u0438\u0442\u044c\u0441\u044f\n",
        "114484 \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435\u2026\n",
        "119388 \u043d\u0435\u0449\u0430\u0441\u0442\u043d\u044b\u0439\n",
        "25587 \u0440\u0430\u0441\u0442\u044f\u0436\u0438\u043c\u043e\u0441\u0442\u044c\n",
        "41783 \u0433\u0440\u044b\u0437\u0443\u043d\n",
        "349772 \u0433\u0430\u043c\u0431\u0443\u0440\u0433-\u0430\u043c\u0435\u0440\u0438\u043a\u0430\n",
        "302585 \u043f\u0435\u0447\u044c\u2026\n",
        "77044 \u0440\u0443\u0431\u0438\u0449\u0435\n",
        "112629 woods\n",
        "238194 spiders\n",
        "91925 \u0433\u043e\u0432\u044f\u0434\u043e\n",
        "179295 woody\n",
        "380356 \u00e3\u00ee\u00ec\u00f3\n",
        "339596 regularize\n",
        "74502 \u0441\u0438\u043d\u043e\u0434\u0438\u0447\u0435\u0441\u043a\u0438\u0439\n",
        "301263 canes\n",
        "92191 \u0441\u0435\u043b\u0435\u0432\u043a\n",
        "117170 \u043e\u0431\u0435\u0437\u0441\u0438\u043b\u0438\u0442\u044c\n",
        "55289 \u043f\u0438\u0441\u0430-\n",
        "40469 \u0437\u0430\u043a\u0430\u043c\u0435\u043d\u0435\u0442\u044c\n",
        "354688 \u0441\u043e\u043a\u0440\u0430\u0449\u0435\u043d\u043d\u043e\u043c\u044a\n",
        "402688 \u00ea\u00ee\u00ec\u00e0\n",
        "159398 \u043d\u0430\u0434\u0440\u0443\u0431\u0438\u0442\u044c\n",
        "88673 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u044b\u044b\u0439\n",
        "296042 \u043f\u043b\u044b\u0439\n",
        "256267 \u043e\u0441\u0432\u0435\u0442\u043b\u0435\u043d\u0438\u0435\n",
        "155565 \u043f\u0440\u043e\u0442\u0435\u043a\u0446\u0456\u043e\u043d\u0438\u0437\u043c\u044a\n",
        "206075 \u043f\u043b\u044b\u0432\n",
        "435124 \u00ef\u00ee\u00e2\u00ee\u00e4\u00e0\u00ec\n",
        "250327 \u0441\u043f\u0440\u0438\u044f\u043d\u043d\u0438\u0439\n",
        "351571 \u043a\u043e\u0440\u0441\u0443\u043d\u0435\u0446\n",
        "370923 enseveli\n",
        "143547 \u043a\u043e\u043d\u0447\u0438\u043b\u0438\u2026\n",
        "336931 \u00ff\u00e7\u00fb\u00ea\u00e0\u00f5\n",
        "71883 \u0437\u0430\u0432\u00ac\n",
        "404197 \u0430\u043d\u043a\u0438\u043b\n",
        "215761 transvestism\n",
        "427017 \u00ff\u00e7\u00fb\u00ea\u00e0\u00ec\n",
        "206522 \u0447\u0430\u0441\u0442\u043d\u043e\u0445\u043e\u0437\u044f\u0439\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0439\n",
        "351049 \u0434\u0435\u0434\u044f\u043a\n",
        "365094 \u043e\u0442\u0447\u0443\u0436\u0434\u0438\u0442\u044c\n",
        "9730 \u0434\u043e\u043b\u0435\u0442\u0435\u0442\u044c\n",
        "256887 \u044d\u0434\u043e\u043c\u0438\u0442\u044f\u043d\u0438\u043d\n",
        "227043 wooded\n",
        "362478 grueling\n",
        "81108 \u0442\u043e\u043c\u043d\u044b\u0439\n",
        "267720 radkey\n",
        "53641 \u0433\u043b\u043e\u0442\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0439\n",
        "200724 \u0435\u043a\u0430\u0442\u0435\u0440\u0438\u043d\u043e-\n",
        "326136 \u00ea\u00ee\u00ec\u00bf\n",
        "199749 raoul\n",
        "430034 \u043f\u0440\u0438\u043c\u0430\u044f\u0442\u044c\n",
        "405835 \u044d\u0442\u043d\u0430\u0440\u0445\n",
        "372395 assignats\n",
        "423526 \u00e4\u00e2\u00e5\u00ed\u00e0\u00e4\u00f6\u00e0\u00f2\u00fc\u00fe\n",
        "43856 \u0437\u043e\u0440\u043e\u0430\u0441\u0442\u0440\u0438\u0435\u0446\n",
        "270571 \u043a\u0430\u043c\u043d\u0435\u0434\u0440\u043e\u0431\u0438\u043b\u044c\u043d\u044b\u0439\n",
        "233723 immunities\n",
        "409062 \u0441\u0430\u043d\u0438\u0442\u0430\u0440\u043d\u043e-\u0432\u0435\u0442\u0435\u0440\u0438\u043d\u0430\u0440\u043d\u044b\u0439\n",
        "388480 \u043e\u0431\u0448\u0438\u0440\u043d\u043e\u0441\u0442\u0438\u0435\n",
        "60903 \u0434\u0435\u043f\u0443-\n",
        "296820 \u043b\u0435\u043d\u0443\u0430\u0440\n",
        "72696 \u043c\u0430\u0441\u0442\u0435\u0440\u00ac\n",
        "56649 \u043c\u0438\u0434\u043e\u0440\u0430\n",
        "268851 \u0431\u0435\u0437\u0443\u043c\u043d\u043e\u2026\n",
        "299239 \u043c\u043d\u043e\u0433\u043e\u043b\u044e\u0431\u044f\u0449\u0438\u0439\n",
        "211262 122-\u044f\n",
        "128567 \u0444\u0435\u043e\u0434\u0430\u043b\u044c\u043d\u043e-\u043a\u0440\u0435\u043f\u043e\u0441\u0442\u043d\u0438\u0447\u0435\u0441\u043a\u0438\u0439\n",
        "359216 \u0436\u0433\u0435\u043d\u0442\u0438\n",
        "9261 \u0432\u043b\u0430\u0434\u0435\u043b\u0438\u0446\u0430\n",
        "87251 \u043c\u044f\u0441\u044c\n",
        "434396 \u00e2\u00e5\u00f0\u00f3\u00fe\u00f9\u00e5\u00e3\u00ee\n",
        "393482 \u043a\u0443\u043a\u043b\u0430-\u043c\u0430\u0440\u0438\u043e\u043d\u0435\u0442\u043a\u0430\n",
        "233911 laourdas\n",
        "73604 \u043f\u0438\u0441\u0430\u00ac\n",
        "237456 comically\n",
        "200155 \u044d\u043d\u0434\u043e\u043a\u0440\u0438\u043d\u043e\u043b\u043e\u0433\n",
        "35360 \u043c\u043e\u0431\u0435\u0436\u0430\n",
        "295008 \u0440\u0430\u043f\u043f\u043e\n",
        "122022 \u043a\u043e\u0440\u0430\u0437\u0432\u0438\u0442\u044b\u0439\n",
        "297238 provins\n",
        "332587 \u00f0\u00e5\u00f1\u00ef\u00f3\u00e1\u00eb\u00e8\u00ea\u00e0\n",
        "144606 usener\n",
        "68844 \u043f\u043e\u0441\u0442\u044b\u0434\u0438\u0442\u044c\u0441\u044f\n",
        "439592 \u0431\u0435\u0439\u0435\u0440\u0438\u043d\u043a\n",
        "170799 \u043b\u0435\u0433\u0430\u0442\u043e\n",
        "174999 constituency\n",
        "364384 sulzbach\n",
        "338868 \u0431\u0438\u0431\u0438\u0441\u044c\n",
        "287469 \u0441\u0442\u043e\u043c\u044a\n",
        "418756 \u00ef\u00f0\u00e0\u00e7\u00e4\u00ed\u00e5\u00f1\u00f2\u00e2\u00e0\n",
        "378290 \u0437\u0430\u0432.\n",
        "227690 \u0437\u0430\u0432-\n",
        "198828 \u0444\u043b\u0430\u043c\u0430\u043d\n",
        "248822 \u0433\u043e\u0441\u043f\u043e\u0434\u0430\u0440\u0441\u0442\u0432\u0456\n",
        "164677 ulpia\n",
        "221865 \u0442\u0430\u043a-\u0442\u0430\u043a-\u0442\u0430\u043a\n",
        "154964 \u0440\u0430\u0437\u0440\u0463\u0448\u0435\u043d\u0456\u0442\u044c\n",
        "281936 \u043c\u0443\u0436\u0435\u0441\u043a\u0430\u0433\u043e\n",
        "164131 \u043a\u0430\u043f\u0440\u0435\u043c\u043e\u043d\u0442\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "def save_data(fname, data):\n",
    "    output = open(fname, 'wb')\n",
    "    pkl.dump(data, output)\n",
    "    output.close()  \n",
    "    \n",
    "def load_data(fname):\n",
    "    inp = open(fname, 'rb')\n",
    "    d = pkl.load(inp)\n",
    "    inp.close()\n",
    "    return d\n",
    "\n",
    "import nltk.corpus\n",
    "from nltk import decorators\n",
    "import nltk.stem\n",
    "import string \n",
    "import pymorphy2\n",
    "\n",
    "punctuations = list(string.punctuation)\n",
    "#stemmer = nltk.stem.snowball.RussianStemmer()\n",
    "stopwords = nltk.corpus.stopwords.words('russian')\n",
    "stopwords += punctuations\n",
    "stopwords += [u'--', u'...', u'—', u'г.', u'тасс', u'риа', u'', u'из-за', u'новость']\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "# remove all tokenz that:\n",
    "# 1. occur only in one doc\n",
    "# 2. Occur more than in 30%(x%) of docs\n",
    "\n",
    "def clear_token(token):\n",
    "    return token.replace(u\"«\", u'').replace(u\"»\", u'').replace(u\"`\", u'').replace(u\"'\", u'').replace(u\"/\", u'')\n",
    "\n",
    "def is_ok_token(token):\n",
    "    if token in stopwords: return False\n",
    "    if not any(c.isalpha() for c in token): return False\n",
    "    return True\n",
    "    \n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [clear_token(x) for x in [morph.parse(item)[0].normal_form for item in tokens] if is_ok_token(x)]\n",
    "\n",
    "\n",
    "'''remove punctuation, lowercase, stem'''\n",
    "def normalize(text):\n",
    "    t = text.lower()\n",
    "    return stem_tokens(nltk.word_tokenize(t))\n",
    "\n",
    "def print_topics(topics):\n",
    "    idx = 1\n",
    "    for l in topics:\n",
    "        print \"{}>>> \".format(idx),\n",
    "        idx += 1\n",
    "        for t in l:\n",
    "            print u\"{}:{} \".format(t[0], t[1]),\n",
    "        print\n",
    "        print\n",
    "        \n",
    "def topic_msgs(topic, num=10):\n",
    "    cnt = 0\n",
    "    for j in topics[topic]:\n",
    "        cnt += 1\n",
    "        print u\"{}({}):{}\".format(j[0], j[1], res[j[0]])\n",
    "        if cnt > num: break \n",
    "\n",
    "import os\n",
    "import codecs\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "def walkdir(folder):\n",
    "    \"\"\"Walk through each files in a directory\"\"\"\n",
    "    for dirpath, dirs, files in os.walk(folder):\n",
    "        for filename in files:\n",
    "            yield os.path.abspath(os.path.join(dirpath, filename))\n",
    "\n",
    "def get_texts_from_dir(dname, extension=None):\n",
    "    texts = []\n",
    "    fls = 0\n",
    "    read = 0\n",
    "    proceed = 0\n",
    "    wrong_enc = 0\n",
    "\n",
    "    # calculate total number\n",
    "    filecounter = 0\n",
    "    for filepath in walkdir(dname):\n",
    "        filecounter += 1\n",
    "    # set bar object\n",
    "    t = tqdm_notebook(walkdir(dname), total=filecounter, unit=\"files\")\n",
    "    for fname in t:\n",
    "        fls += 1\n",
    "        if extension is not None:\n",
    "            if not fname.endswith(extension):\n",
    "                continue\n",
    "        read += 1\n",
    "        try:\n",
    "            fl = codecs.open(fname, encoding='utf-8')\n",
    "            body = fl.read()\n",
    "        except UnicodeDecodeError:\n",
    "            wrong_enc += 1\n",
    "            continue\n",
    "        if body.startswith(u\"Document Outline\"):\n",
    "            continue\n",
    "        proceed += 1\n",
    "        texts.append((fname, normalize(body)))\n",
    "        t.set_postfix(Files=fls, Read=read, Proceed=proceed, Wrong_encoded=wrong_enc)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "          \r",
      "103/|/  0%|| 103/66280 [02:28<26:31:33,  1.44s/files, Files=103, Proceed=21, Read=24, Wrong_encoded=1]\r",
      "          \r",
      "228/|/  0%|| 228/66280 [05:38<27:16:26,  1.49s/files, Files=157, Proceed=30, Read=35, Wrong_encoded=1]\r",
      "          \r",
      "609/|/  1%|| 609/66280 [31:12<56:05:00,  3.07s/files, Files=567, Proceed=70, Read=112, Wrong_encoded=1]\r",
      "          \r",
      "1527/|/  2%|| 1527/66280 [48:35<34:20:29,  1.91s/files, Files=1.44e+03, Proceed=112, Read=280, Wrong_encoded=1]\r",
      "          \r",
      "1840/|/  3%|| 1840/66280 [50:55<29:43:38,  1.66s/files, Files=1.86e+03, Proceed=120, Read=372, Wrong_encoded=1]\r",
      "          \r",
      "2232/|/  3%|| 2232/66280 [58:06<27:47:38,  1.56s/files, Files=2.2e+03, Proceed=136, Read=437, Wrong_encoded=1]\r",
      "          \r",
      "2385/|/  4%|| 2385/66280 [58:47<26:14:51,  1.48s/files, Files=2.31e+03, Proceed=137, Read=462, Wrong_encoded=1]\r",
      "          \r",
      "3773/|/  6%|| 3773/66280 [2:10:35<36:03:33,  2.08s/files, Files=3.77e+03, Proceed=241, Read=743, Wrong_encoded=1]\r",
      "          \r",
      "5446/|/  8%|| 5446/66280 [5:02:44<56:21:39,  3.34s/files, Files=5.45e+03, Proceed=494, Read=1.07e+03, Wrong_encoded=5]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-9d1147b8ee40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create texts collection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_texts_from_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Volumes/Backup/Calibre/Sept-2018/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msave_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Volumes/Backup/Calibre/texts.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-420f4f10dcce>\u001b[0m in \u001b[0;36mget_texts_from_dir\u001b[0;34m(dname, extension)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mproceed\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mtexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProceed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproceed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWrong_encoded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwrong_enc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-420f4f10dcce>\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstem_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-57-420f4f10dcce>\u001b[0m in \u001b[0;36mstem_tokens\u001b[0;34m(tokens)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstem_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclear_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmorph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_form\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_ok_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pymorphy2/analyzer.pyc\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_terminal\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_units\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_terminal\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pymorphy2/units/by_lookup.pyc\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, word, word_lower, seen_parses)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mnormal_forms_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mpara_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilar_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mee\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfixed_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparses\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpara_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/dawg_python/dawgs.pyc\u001b[0m in \u001b[0;36msimilar_items\u001b[0;34m(self, key, replaces)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0municode\u001b[0m \u001b[0mstrings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \"\"\"\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_similar_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mROOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplaces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/dawg_python/dawgs.pyc\u001b[0m in \u001b[0;36m_similar_items\u001b[0;34m(self, current_prefix, key, index, replace_chars)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                 \u001b[0mfound_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_pos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_for_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfound_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/dawg_python/dawgs.pyc\u001b[0m in \u001b[0;36m_value_for_index\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_for_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRecordDAWG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_for_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_struct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/dawg_python/dawgs.pyc\u001b[0m in \u001b[0;36m_value_for_index\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mcompleter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0;32mwhile\u001b[0m \u001b[0mcompleter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m             \u001b[0;31m# a2b_base64 doesn't support bytearray in python 2.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;31m# so it is converted (and copied) to bytes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/dawg_python/wrapper.pyc\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                     \u001b[0msibling_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_guide\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msibling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m                     \u001b[0;31m# Moves to the previous node.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create texts collection\n",
    "texts = get_texts_from_dir('/Volumes/Backup/Calibre/Sept-2018/', '.txt')\n",
    "save_data('/Volumes/Backup/Calibre/texts.pkl', texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make dict and corpus\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.3, keep_n=None)\n",
    "dictionary.compactify()\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# lda\n",
    "lda = models.ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=100, alpha='auto',  passes=5, iterations=10)\n",
    "\n",
    "# viz\n",
    "import pyLDAvis.gensim\n",
    "data = pyLDAvis.gensim.prepare(lda, corpus, dictionary)\n",
    "pyLDAvis.display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Document Outline\".startswith('qwe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filecounter = 0\n",
    "for filepath in walkdir('/Volumes/Backup/Calibre/Sept-2018/'):\n",
    "    filecounter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sleep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-924e62c1eef1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sleep' is not defined"
     ]
    }
   ],
   "source": [
    "t = tqdm_notebook(walkdir('/Volumes/Backup/Calibre/Sept-2018/'), total=66280, unit=\"files\")\n",
    "for fname in t:\n",
    "    t.set_postfix(File=fname)\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len (texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
